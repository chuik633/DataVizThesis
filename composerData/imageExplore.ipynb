{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import colorsys\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from os import listdir\n",
    "from PIL import Image as PImage\n",
    "\n",
    "from utils.image_utils import *\n",
    "from utils.data_utils import GaussianClustering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_saturation(c):\n",
    "    r, g, b = c[0] / 255.0, c[1] / 255.0, c[2] / 255.0\n",
    "    hsv = colorsys.rgb_to_hsv(r,g,b)\n",
    "    return hsv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_colors_clusters(imgPath): \n",
    "    # get image and convert pixels into a dataframe\n",
    "    pimg = PImage.open(imgPath).convert(\"RGB\")\n",
    "    pxs = get_pixels(pimg)\n",
    "    pxs_df = pd.DataFrame(pxs, columns = ['R', 'G', 'B'])\n",
    "    print(\"got pixels\")\n",
    "    \n",
    "\n",
    "    # create clustering model\n",
    "    model = GaussianClustering(n_clusters = 8) #get 8 colors first\n",
    "    predicted = model.fit_predict(pxs_df[['R', 'G', 'B']])\n",
    "    print(\"trained model\")\n",
    "\n",
    "    # post process clustering result\n",
    "    ccounts = predicted['clusters'].value_counts()\n",
    "    colors = []\n",
    "    for clusterNum in ccounts.index[:5]:\n",
    "        r,g,b = model.cluster_centers_[clusterNum]\n",
    "        colors.append([round(r), round(g), round(b)])\n",
    "    print('getting color info')\n",
    "\n",
    "    sorted_colors = sorted(colors, key=rgb_to_saturation, reverse=True)\n",
    "\n",
    "    return sorted_colors, pxs_df, colors, predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sorted_colors, pxs_df, colors = \u001b[43mget_main_colors_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./tmp/past.png\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mget_main_colors_clusters\u001b[39m\u001b[34m(imgPath)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# create clustering model\u001b[39;00m\n\u001b[32m      9\u001b[39m model = GaussianClustering(n_clusters = \u001b[32m8\u001b[39m) \u001b[38;5;66;03m#get 8 colors first\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m predicted = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpxs_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mG\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mB\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# post process clustering result\u001b[39;00m\n\u001b[32m     13\u001b[39m ccounts = predicted[\u001b[33m'\u001b[39m\u001b[33mclusters\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/utils/data_utils.py:234\u001b[39m, in \u001b[36mClusterer.fit_predict\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isDataFrame(X):\n\u001b[32m    232\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput has wrong type. Please use pandas DataFrame\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.X = X.values\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.y = y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/myenv/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/myenv/lib/python3.13/site-packages/sklearn/mixture/_base.py:246\u001b[39m, in \u001b[36mBaseMixture.fit_predict\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.max_iter + \u001b[32m1\u001b[39m):\n\u001b[32m    244\u001b[39m     prev_lower_bound = lower_bound\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     log_prob_norm, log_resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_e_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     \u001b[38;5;28mself\u001b[39m._m_step(X, log_resp)\n\u001b[32m    248\u001b[39m     lower_bound = \u001b[38;5;28mself\u001b[39m._compute_lower_bound(log_resp, log_prob_norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/myenv/lib/python3.13/site-packages/sklearn/mixture/_base.py:305\u001b[39m, in \u001b[36mBaseMixture._e_step\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_e_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    290\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"E step.\u001b[39;00m\n\u001b[32m    291\u001b[39m \n\u001b[32m    292\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m \u001b[33;03m        the point of each sample in X.\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m     log_prob_norm, log_resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_log_prob_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(log_prob_norm), log_resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/myenv/lib/python3.13/site-packages/sklearn/mixture/_base.py:525\u001b[39m, in \u001b[36mBaseMixture._estimate_log_prob_resp\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_log_prob_resp\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    507\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[32m    508\u001b[39m \n\u001b[32m    509\u001b[39m \u001b[33;03m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m \u001b[33;03m        logarithm of the responsibilities\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     weighted_log_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_weighted_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m     log_prob_norm = logsumexp(weighted_log_prob, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(under=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    528\u001b[39m         \u001b[38;5;66;03m# ignore underflow\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/myenv/lib/python3.13/site-packages/sklearn/mixture/_base.py:478\u001b[39m, in \u001b[36mBaseMixture._estimate_weighted_log_prob\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_weighted_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    468\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[32m    469\u001b[39m \n\u001b[32m    470\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    476\u001b[39m \u001b[33;03m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[32m    477\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_estimate_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m._estimate_log_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/myenv/lib/python3.13/site-packages/sklearn/mixture/_gaussian_mixture.py:820\u001b[39m, in \u001b[36mGaussianMixture._estimate_log_prob\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_log_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_log_gaussian_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmeans_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecisions_cholesky_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcovariance_type\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DataVisualization/MajorStudio2/DataVizThesis/composerData/myenv/lib/python3.13/site-packages/sklearn/mixture/_gaussian_mixture.py:481\u001b[39m, in \u001b[36m_estimate_log_gaussian_prob\u001b[39m\u001b[34m(X, means, precisions_chol, covariance_type)\u001b[39m\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, (mu, prec_chol) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(means, precisions_chol)):\n\u001b[32m    480\u001b[39m         y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n\u001b[32m--> \u001b[39m\u001b[32m481\u001b[39m         log_prob[:, k] = np.sum(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m covariance_type == \u001b[33m\"\u001b[39m\u001b[33mtied\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    484\u001b[39m     log_prob = np.empty((n_samples, n_components))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "sorted_colors, pxs_df, colors, predicted = get_main_colors_clusters('./tmp/past.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotting\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(pxs_df['R'], pxs_df['G'], pxs_df['B'], c=predicted, s=1, alpha=0.5)\n",
    "ax.set_xlabel('R')\n",
    "ax.set_ylabel('G')\n",
    "ax.set_zlabel('B')\n",
    "for idx, color in enumerate(colors):\n",
    "    ax.scatter(color[0], color[1], color[2], c=[color], marker='o', s=100, label=f\"Cluster {idx+1}\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_colors(imgPath,  color_similarity_threshold = 100):\n",
    "    pimg =  PImage.open(imgPath).convert(\"RGB\")\n",
    "    pxs = get_pixels(pimg)\n",
    "\n",
    "    main_colors = []\n",
    "    def color_distance(c1, c2):\n",
    "        d = 0\n",
    "        for i in range(len(c1)):\n",
    "            d += (c1[i]-c2[i])**2\n",
    "        d = d**.5\n",
    "        return d\n",
    "\n",
    "    def color_unique(c):\n",
    "        for existing_color in main_colors:\n",
    "            dist = color_distance(existing_color, c) \n",
    "            # print(dist)\n",
    "            if dist < color_similarity_threshold: \n",
    "                return False, existing_color\n",
    "        \n",
    "        return True, c\n",
    "\n",
    "    for color in pxs:\n",
    "        unique, color = color_unique(color)\n",
    "\n",
    "        if unique:\n",
    "            main_colors.append(color)\n",
    "\n",
    "    main_colors = [list(c) for c in main_colors]\n",
    "    sorted_colors = sorted(main_colors, key=rgb_to_saturation, reverse=True)\n",
    "    return sorted_colors[:10]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
